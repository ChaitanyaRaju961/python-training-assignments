{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6678784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences:\n",
      "- \n",
      "Natural Language Processing (NLP) is a field of artificial intelligence that enables computers \n",
      "to understand, interpret, and generate human language.\n",
      "- With NLP, we can process text, \n",
      "analyze sentiments, translate languages, and even generate text like this!\n",
      "- It is a growing field with many exciting opportunities.\n",
      "\n",
      "Tokenized Words:\n",
      "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'enables', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'With', 'NLP', ',', 'we', 'can', 'process', 'text', ',', 'analyze', 'sentiments', ',', 'translate', 'languages', ',', 'and', 'even', 'generate', 'text', 'like', 'this', '!', 'It', 'is', 'a', 'growing', 'field', 'with', 'many', 'exciting', 'opportunities', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rajuc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')\n",
    "paragraph = \"\"\"\n",
    "Natural Language Processing (NLP) is a field of artificial intelligence that enables computers \n",
    "to understand, interpret, and generate human language. With NLP, we can process text, \n",
    "analyze sentiments, translate languages, and even generate text like this! \n",
    "It is a growing field with many exciting opportunities.\n",
    "\"\"\"\n",
    "sentences = sent_tokenize(paragraph)\n",
    "words = word_tokenize(paragraph)\n",
    "print(\"Tokenized Sentences:\")\n",
    "for sentence in sentences:\n",
    "    print(f\"- {sentence}\")\n",
    "print(\"\\nTokenized Words:\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda516f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
